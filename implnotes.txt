====================
Implementation Notes
====================

-------
General
-------

Caveats:
      cf. file "abinotes.txt" included with this source code.

Further Notes:

- I decided to use ENTER for clarity instead of the regular

        PUSH    RBP
        MOV     RBP, RSP

  as function prologue, despite the size/speed tradeoff.

-------------
Build Process
-------------

- Refer to makefile to see how individual files are built.

- Some files are generated by Perl scripts and are not part of the repository.

- Clone the repository using 'git clone --recursive URL', this will make sure
  the ebnfcomp submodule is cloned as well, which is required for building.

- Dependencies in makefile might be incomplete; use 'make -B' to do a full
  rebuild.

- If at any point, a build error occurs, please let me know, so that I can have
  a look at it.

- The font is defined in the file "8x12font1.txt", which is converted to a hex
  dump in file "8x12font1.inc" by the "extract_font.pl" script.
  "8x12font1.inc" is included by "8x12font1.nasm".

- The token list (actually, keyword list) is defined in file "tokenlist.txt".
  It is used by script "extract_tl.pl" to generate "tokendef.inc", which is
  included by "tokens.nasm". It is also read by "build_main_ebnf.pl" to create
  the token-based (binary) EBNF. See chapter "Tokenization Process" to read
  more about the tokenization process.

- The main language syntax comes from the file "defaultsyntax.ebnf". It is read
  by "build_main_ebnf.pl" to create "main.ebnf", which is the main language EBNF
  file, matching against binary tokens as opposed to text. This "main.ebnf" file
  is then run through the EBNF compiler (ebnfcomp) to generate "mainsyntax.inc"
  and "mainsyntax.nasm", which is the parsing table. See chapter "Syntax
  Analysis" to see how it works.

--------------------
Tokenization Process
--------------------

- Input lines are fully converted to tokens before being run through the syntax
  analyzer.

- Cf. file "build_main_ebnf.pl" to see how individual tokens are encoded.

- Anything that is not recognized will be converted to an identifier.
  Identifiers are encoded as FE TYPE LEN ...

- Number tokens are encoded as 01 BASE VALUE.q
  NOTE that VALUE is encoded in big endian (network byte order).

- Operator tokens are hardcoded in the tokenization process.
  They are encoded as 02 ID

- Currently, there is a maximum of 256 keywords.
  They are encoded as 03 ID
  The keyword list is specified 'tokenlist.txt' and used during the build
  process. Order affects the ID assigned to each keyword, thus as soon as
  there are users of AsmBASIC, new ones should only ever be appended, never
  inserted at arbitrary positions into the file.

- String literals are encoded as FF LEN.w ...
  NOTE that LEN is encoded in big endian (network byte order).

-----------------------
Syntax Analysis Process
-----------------------

- Syntax analysis (in "syntree.nasm") uses the in-memory parsing tree created
  in "parsetree.nasm".

- Syntax tree nodes are presently just pointers to the matching parse tree nodes
  (and token bytes, if any), and a list of subnodes.

- Some optimizations are applied to reduce the overall number of result nodes in
  the tree. The goal here is so complexity becomes minimal for later code
  generation.

- A "cooked syntax tree" (csn tree) is created from the "raw syntax tree" (stn
  tree) that makes objects from the syntax tree more directly accessible, and
  also employs some further optimizations. Beginnings (i.e., root nodes) of
  statements and expressions are clearly marked. This makes code generation
  much easier.
